{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ccb10a-43ca-4a1d-8efb-71dac46cfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "\n",
    "file_path ='/home/akurdi/Desktop/SDP/datasetcsv'\n",
    "\n",
    "print ('is folder found')\n",
    "print (os.path.exists(file_path))\n",
    "\n",
    "orinigal_dataset_path=[]\n",
    "for dirname, _, filenames in os.walk(file_path):\n",
    "    print(dirname)\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        if filename.endswith ('csv') :\n",
    "            orinigal_dataset_path.append(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3b8ff-d100-443f-9aa2-9149b08e2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "print('number of dataset' , len (orinigal_dataset_path))\n",
    "\n",
    "dataSets =[]\n",
    "\n",
    "for dataset in orinigal_dataset_path:\n",
    "    print(dataset)\n",
    "    orig_df = pd.read_csv(dataset)\n",
    "    print(orig_df.shape)\n",
    "    # orig_df.head(3)\n",
    "   \n",
    "    orig_df.replace( '?', 0, inplace=True)\n",
    "    # Assuming 'orig_df' is your dataframe and 'defects' contains True/False values\n",
    "    # orig_df['class'] = orig_df['class'].astype(int)\n",
    "    if 'class' in orig_df.columns:\n",
    "        orig_df['class'] = orig_df['class'].replace({'clean': 0, 'buggy': 1}).astype(int)\n",
    "        X = orig_df.drop('class', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['class']               # Target column\n",
    "        orig_df.rename(columns={'class': 'defects'}, inplace=True)\n",
    "    elif 'defects' in orig_df.columns:\n",
    "        orig_df['defects'] = orig_df['defects'].astype(int)\n",
    "        X = orig_df.drop('defects', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['defects']               # Target column\n",
    "    elif 'bug' in orig_df.columns:\n",
    "        X = orig_df.drop('bug', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['bug']\n",
    "        orig_df.rename(columns={'bug': 'defects'}, inplace=True)\n",
    "    elif 'isDefective' in orig_df.columns:\n",
    "        orig_df['isDefective'] = orig_df['isDefective'].replace({'clean': 0, 'buggy': 1}).astype(int)\n",
    "        X = orig_df.drop('isDefective', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['isDefective']\n",
    "        orig_df.rename(columns={'isDefective': 'defects'}, inplace=True)\n",
    "    elif 'Defective' in orig_df.columns:\n",
    "        orig_df['Defective'] = orig_df['Defective'].replace({'N': 0, 'Y': 1}).astype(int)\n",
    "        X = orig_df.drop('Defective', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['Defective']\n",
    "        orig_df.rename(columns={'Defective': 'defects'}, inplace=True)\n",
    "    elif 'c' in orig_df.columns:\n",
    "        orig_df['c'] = orig_df['c'].astype(int)\n",
    "        X = orig_df.drop('c', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['c']    \n",
    "        orig_df.rename(columns={'c': 'defects'}, inplace=True)\n",
    "\n",
    "    # Rename the target column y to defects\n",
    "    y = orig_df['defects']\n",
    "    dataSets.append(orig_df)\n",
    "    print(orig_df[X.columns].apply(pd.to_numeric, errors='coerce').isnull().sum())\n",
    "\n",
    "    # Assuming 'orig_df' is your dataset and it has features and a target column\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0e7f6-74ea-41d9-850e-8f666d354cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "for dataset in dataSets:\n",
    "    # print(dataset)\n",
    "    X = orig_df.drop('defects', axis=1)  \n",
    "    y = orig_df['defects']\n",
    "    model.fit(X,y)\n",
    "    print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feat_importances.nlargest(35).plot(kind='barh')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccdb89-2cee-4309-9ab4-da30dff28f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "         # Target column\n",
    "\n",
    "\n",
    "# Initialize KFold with 20 splits\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=5)\n",
    "\n",
    "\n",
    "# Lists to store the metrics for each fold\n",
    "\n",
    "\n",
    "# Define different gamma and C values for the RBF kernel (4 combinations)\n",
    "gamma_values = [0.01, 0.1, 1, 10]  # You can adjust these gamma values\n",
    "C_values = [0.1, 1, 10, 100]       # You can adjust these C values\n",
    "\n",
    "# Loop through the different kernel variations (RBF with different gamma and C)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for dataset in dataSets:\n",
    "    \n",
    "    # Assuming 'orig_df' is your dataset and it has features and a target column\n",
    "    X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "    # print(dataset[X.columns].apply(pd.to_numeric, errors='coerce').isnull().sum())\n",
    "    y = dataset['defects']\n",
    "\n",
    "    # To store results of each fold (optional)\n",
    "    for gamma, C in zip(gamma_values, C_values):\n",
    "        fold_num = 1\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "        # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "            # Initialize the SVM model with RBF kernel and the current gamma, C values\n",
    "            clf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        \n",
    "            # Train the model on the training data\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the test data\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "            DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "            DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # Append metrics to lists\n",
    "            accuracies.append(DT_accuracy)\n",
    "            precisions.append(DT_precision)\n",
    "            recalls.append(DT_recall)\n",
    "            f1_scores.append(DT_f1)\n",
    "\n",
    "            # Print metrics for this kernel variation\n",
    "            print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "            print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "            print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "            print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "            print(\"-\" * 30)\n",
    "            fold_num += 1\n",
    "\n",
    "        print(f\"Fold {fold_num}, RBF Kernel with gamma={gamma} and C={C}:\")\n",
    "        # After all folds, calculate the mean and standard deviation of each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "\n",
    "        # Print the compiled results\n",
    "        print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "        print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "        print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "        print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "\n",
    "# After all folds, calculate the mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_precision = np.std(precisions)\n",
    "std_recall = np.std(recalls)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the compiled results\n",
    "print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd5935-9abf-444c-8379-46d62830c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize KFold with 20 splits\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "\n",
    "# Lists to store the metrics for each fold\n",
    "\n",
    "\n",
    "# Define different gamma and C values for the RBF kernel (4 combinations)\n",
    "gamma_values = [0.01, 0.1, 1, 10]  # You can adjust these gamma values\n",
    "C_values = [0.1, 1, 10, 100]       # You can adjust these C values\n",
    "\n",
    "# Loop through the different kernel variations (RBF with different gamma and C)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for dataset in dataSets:\n",
    "    \n",
    "    # Assuming 'orig_df' is your dataset and it has features and a target column\n",
    "    X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "    # print(dataset[X.columns].apply(pd.to_numeric, errors='coerce').isnull().sum())\n",
    "    y = dataset['defects']\n",
    "\n",
    "    # To store results of each fold (optional)\n",
    "    for gamma, C in zip(gamma_values, C_values):\n",
    "        fold_num = 1\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "            # Initialize ExtraTreesClassifier for feature selection\n",
    "            model = ExtraTreesClassifier(random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            num_features_to_select = int(0.7 * X_train.shape[1])\n",
    "            feature_importances = model.feature_importances_\n",
    "            indices = np.argsort(feature_importances)[::-1]  # Get indices of the sorted feature importances in descending order\n",
    "            selected_features = X_train.columns[indices[:num_features_to_select] ]  # Select the corresponding feature names\n",
    "            print(f\"Top \",num_features_to_select, selected features: {list(selected_features)}\")\n",
    "\n",
    "            # Transform the train and test sets to only include the selected features\n",
    "            X_train_selected = X_train[selected_features]\n",
    "            X_test_selected = X_test[selected_features]\n",
    "\n",
    "            # Plot graph of feature importances only for selected features\n",
    "            selected_feat_importances = pd.Series(feature_importances, index=X_train.columns)[selected_features]\n",
    "            selected_feat_importances.sort_values(ascending=False).plot(kind='barh')\n",
    "            plt.title(\"Feature Importances for Selected Features top\")\n",
    "            plt.show()\n",
    "\n",
    "            # Initialize the SVM model\n",
    "            clf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "\n",
    "            # Train the SVM model on the selected features\n",
    "            clf.fit(X_train_selected, y_train)\n",
    "    \n",
    "            # Predict on the test data with selected features\n",
    "            y_pred = clf.predict(X_test_selected)\n",
    "    \n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "            # Calculate metrics\n",
    "            DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "            DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "            DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # Append metrics to lists\n",
    "            accuracies.append(DT_accuracy)\n",
    "            precisions.append(DT_precision)\n",
    "            recalls.append(DT_recall)\n",
    "            f1_scores.append(DT_f1)\n",
    "\n",
    "            # Print metrics for this kernel variation\n",
    "            print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "            print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "            print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "            print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "            print(\"-\" * 30)\n",
    "            fold_num += 1\n",
    "\n",
    "        print(f\"Fold {fold_num}, RBF Kernel with gamma={gamma} and C={C}:\")\n",
    "        # After all folds, calculate the mean and standard deviation of each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "\n",
    "        # Print the compiled results\n",
    "        print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "        print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "        print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "        print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "\n",
    "# After all folds, calculate the mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_precision = np.std(precisions)\n",
    "std_recall = np.std(recalls)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the compiled results\n",
    "print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82888e4-ee6f-4cb7-b1a3-e25bcc0d58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize KFold with 20 splits\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=5)\n",
    "\n",
    "\n",
    "# Lists to store the metrics for each fold\n",
    "\n",
    "\n",
    "# Define different gamma and C values for the RBF kernel (4 combinations)\n",
    "gamma_values = [0.01, 0.1, 1, 10]  # You can adjust these gamma values\n",
    "C_values = [0.1, 1, 10, 100]       # You can adjust these C values\n",
    "\n",
    "# Loop through the different kernel variations (RBF with different gamma and C)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for dataset in dataSets:\n",
    "    \n",
    "    # Assuming 'orig_df' is your dataset and it has features and a target column\n",
    "    X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "    # print(dataset[X.columns].apply(pd.to_numeric, errors='coerce').isnull().sum())\n",
    "    y = dataset['defects']\n",
    "\n",
    "    # To store results of each fold (optional)\n",
    "    for gamma, C in zip(gamma_values, C_values):\n",
    "        fold_num = 1\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "            # Initialize ExtraTreesClassifier for feature selection\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            num_features_to_select = int(0.7 * X_train.shape[1])\n",
    "            feature_importances = model.feature_importances_\n",
    "            indices = np.argsort(feature_importances)[::-1]  # Get indices of the sorted feature importances in descending order\n",
    "            selected_features = X_train.columns[indices[:num_features_to_select] ]  # Select the corresponding feature names\n",
    "                    # Calculate number of features to select as 60% of total features\n",
    "\n",
    "            print(f\"Top \",num_features_to_select,\" selected features: {list(selected_features)}\")\n",
    "\n",
    "            # Transform the train and test sets to only include the selected features\n",
    "            X_train_selected = X_train[selected_features]\n",
    "            X_test_selected = X_test[selected_features]\n",
    "\n",
    "            # Plot graph of feature importances only for selected features\n",
    "            selected_feat_importances = pd.Series(feature_importances, index=X_train.columns)[selected_features]\n",
    "            selected_feat_importances.sort_values(ascending=False).plot(kind='barh')\n",
    "            plt.title(\"Feature Importances for Selected Features top\")\n",
    "            plt.show()\n",
    "\n",
    "            # Initialize the SVM model\n",
    "            clf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "\n",
    "            # Train the SVM model on the selected features\n",
    "            clf.fit(X_train_selected, y_train)\n",
    "    \n",
    "            # Predict on the test data with selected features\n",
    "            y_pred = clf.predict(X_test_selected)\n",
    "    \n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "            # Calculate metrics\n",
    "            DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "            DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "            DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # Append metrics to lists\n",
    "            accuracies.append(DT_accuracy)\n",
    "            precisions.append(DT_precision)\n",
    "            recalls.append(DT_recall)\n",
    "            f1_scores.append(DT_f1)\n",
    "\n",
    "            # Print metrics for this kernel variation\n",
    "            print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "            print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "            print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "            print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "            print(\"-\" * 30)\n",
    "            fold_num += 1\n",
    "\n",
    "        print(f\"Fold {fold_num}, RBF Kernel with gamma={gamma} and C={C}:\")\n",
    "        # After all folds, calculate the mean and standard deviation of each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "\n",
    "        # Print the compiled results\n",
    "        print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "        print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "        print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "        print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "\n",
    "# After all folds, calculate the mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_precision = np.std(precisions)\n",
    "std_recall = np.std(recalls)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the compiled results\n",
    "print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbd7a3-1b88-4453-87d0-0ed248f46d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb32082-6044-402d-91c5-7e8f3128eaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
