{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d63a3-6d63-4c69-91b3-534d05dcb2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "\n",
    "file_path ='/home/akurdi/Desktop/SDP/datasetcsv'\n",
    "\n",
    "print ('is folder found')\n",
    "print (os.path.exists(file_path))\n",
    "\n",
    "orinigal_dataset_path=[]\n",
    "for dirname, _, filenames in os.walk(file_path):\n",
    "    print(dirname)\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        if filename.endswith ('csv') :\n",
    "            orinigal_dataset_path.append(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21211a-e7be-4a83-be00-be18d5bb55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "print('number of dataset' , len (orinigal_dataset_path))\n",
    "\n",
    "dataSets =[]\n",
    "\n",
    "for dataset in orinigal_dataset_path:\n",
    "    print(dataset)\n",
    "    orig_df = pd.read_csv(dataset)\n",
    "    print(orig_df.shape)\n",
    "    # orig_df.head(3)\n",
    "   \n",
    "    orig_df.replace( '?', 0, inplace=True)\n",
    "    # Assuming 'orig_df' is your dataframe and 'defects' contains True/False values\n",
    "    # orig_df['class'] = orig_df['class'].astype(int)\n",
    "    if 'class' in orig_df.columns:\n",
    "        orig_df['class'] = orig_df['class'].replace({'clean': 0, 'buggy': 1}).astype(int)\n",
    "        X = orig_df.drop('class', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['class']               # Target column\n",
    "        orig_df.rename(columns={'class': 'defects'}, inplace=True)\n",
    "    elif 'defects' in orig_df.columns:\n",
    "        orig_df['defects'] = orig_df['defects'].astype(int)\n",
    "        X = orig_df.drop('defects', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['defects']               # Target column\n",
    "    elif 'bug' in orig_df.columns:\n",
    "        X = orig_df.drop('bug', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['bug']\n",
    "        orig_df.rename(columns={'bug': 'defects'}, inplace=True)\n",
    "    elif 'isDefective' in orig_df.columns:\n",
    "        orig_df['isDefective'] = orig_df['isDefective'].replace({'clean': 0, 'buggy': 1}).astype(int)\n",
    "        X = orig_df.drop('isDefective', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['isDefective']\n",
    "        orig_df.rename(columns={'isDefective': 'defects'}, inplace=True)\n",
    "    elif 'Defective' in orig_df.columns:\n",
    "        orig_df['Defective'] = orig_df['Defective'].replace({'N': 0, 'Y': 1}).astype(int)\n",
    "        X = orig_df.drop('Defective', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['Defective']\n",
    "        orig_df.rename(columns={'Defective': 'defects'}, inplace=True)\n",
    "    elif 'c' in orig_df.columns:\n",
    "        orig_df['c'] = orig_df['c'].astype(int)\n",
    "        X = orig_df.drop('c', axis=1)  # Features (drop the target column)\n",
    "        y = orig_df['c']    \n",
    "        orig_df.rename(columns={'c': 'defects'}, inplace=True)\n",
    "\n",
    "    # Rename the target column y to defects\n",
    "    y = orig_df['defects']\n",
    "    dataSets.append(orig_df)\n",
    "    print(orig_df[X.columns].apply(pd.to_numeric, errors='coerce').isnull().sum())\n",
    "\n",
    "    # Assuming 'orig_df' is your dataset and it has features and a target column\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a564d-da4c-46b0-9d36-90ddfaedab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "num=1\n",
    "for dataset in dataSets:\n",
    "    print(num)\n",
    "    num=num+1\n",
    "    X = orig_df.drop('defects', axis=1)  \n",
    "    y = orig_df['defects']\n",
    "    model.fit(X,y)\n",
    "    print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feat_importances.nlargest(35).plot(kind='barh')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478c657-2823-4924-bf54-1e78210b0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize KFold with 2 splits (as per your code)\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=5)\n",
    "\n",
    "# Lists to store the metrics for each fold\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Define different n_neighbors values for KNN\n",
    "n_neighbors_values = [12]  # You can adjust these values\n",
    "\n",
    "for dataset in dataSets:\n",
    "    \n",
    "    # Assuming 'dataset' is your dataset and it has features and a target column\n",
    "    X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "    y = dataset['defects']  # Target column\n",
    "\n",
    "    # To store results of each fold (optional)\n",
    "    for n_neighbors in n_neighbors_values:\n",
    "        fold_num = 1\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Initialize the KNN model with the current n_neighbors value\n",
    "            clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "            # Train the model on the training data\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the test data\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "            DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "            DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # Append metrics to lists\n",
    "            accuracies.append(DT_accuracy)\n",
    "            precisions.append(DT_precision)\n",
    "            recalls.append(DT_recall)\n",
    "            f1_scores.append(DT_f1)\n",
    "\n",
    "            # Print metrics for this kernel variation\n",
    "            print(f\"Fold {fold_num} - KNN with n_neighbors={n_neighbors}\")\n",
    "            print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "            print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "            print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "            print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "            print(\"-\" * 30)\n",
    "            fold_num += 1\n",
    "\n",
    "        print(f\"KNN with n_neighbors={n_neighbors}:\")\n",
    "        # After all folds, calculate the mean and standard deviation of each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "\n",
    "        # Print the compiled results\n",
    "        print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "        print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "        print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "        print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "\n",
    "# After all folds, calculate the mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_precision = np.std(precisions)\n",
    "std_recall = np.std(recalls)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the compiled results\n",
    "print(\"Overall Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "print(\"Overall Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "print(\"Overall Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "print(\"Overall Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f717a-a3b0-4b9b-9e3a-57cc9eba8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize KFold with 2 splits (as per your code)\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=5)\n",
    "\n",
    "# Lists to store the metrics for each fold\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Define different n_neighbors values for KNN\n",
    "n_neighbors_values = [4,7,10,15]  # You can adjust these values\n",
    "\n",
    "for dataset in dataSets:\n",
    "   \n",
    "    # Assuming 'dataset' is your dataset and it has features and a target column\n",
    "    X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "    y = dataset['defects']  # Target column\n",
    "\n",
    "    # To store results of each fold (optional)\n",
    "    for n_neighbors in n_neighbors_values:\n",
    "        fold_num = 1\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "            # model = ExtraTreesClassifier(random_state=42)\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            num_features_to_select = int(0.6 * X_train.shape[1])\n",
    "            feature_importances = model.feature_importances_\n",
    "            indices = np.argsort(feature_importances)[::-1]  # Get indices of the sorted feature importances in descending order\n",
    "            selected_features = X_train.columns[indices[:num_features_to_select] ]  # Select the corresponding feature names\n",
    "            print(f\"Top \",num_features_to_select, \"selected features: {list(selected_features)}\")\n",
    "\n",
    "            # Transform the train and test sets to only include the selected features\n",
    "            X_train_selected = X_train[selected_features]\n",
    "            X_test_selected = X_test[selected_features]\n",
    "\n",
    "            # Plot graph of feature importances only for selected features\n",
    "            selected_feat_importances = pd.Series(feature_importances, index=X_train.columns)[selected_features]\n",
    "            selected_feat_importances.sort_values(ascending=False).plot(kind='barh')\n",
    "            plt.title(\"Feature Importances for Selected Features top\")\n",
    "            plt.show()\n",
    "        \n",
    "            \n",
    "            # Initialize the KNN model with the current n_neighbors value\n",
    "            clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "           # Train the SVM model on the selected features\n",
    "            clf.fit(X_train_selected, y_train)\n",
    "    \n",
    "            # Predict on the test data with selected features\n",
    "            y_pred = clf.predict(X_test_selected)\n",
    "\n",
    "            # Calculate metrics\n",
    "            DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "            DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "            DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # Append metrics to lists\n",
    "            accuracies.append(DT_accuracy)\n",
    "            precisions.append(DT_precision)\n",
    "            recalls.append(DT_recall)\n",
    "            f1_scores.append(DT_f1)\n",
    "\n",
    "            # Print metrics for this kernel variation\n",
    "            print(f\"Fold {fold_num} - KNN with n_neighbors={n_neighbors}\")\n",
    "            print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "            print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "            print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "            print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "            print(\"-\" * 30)\n",
    "            fold_num += 1\n",
    "\n",
    "        print(f\"KNN with n_neighbors={n_neighbors}:\")\n",
    "        # After all folds, calculate the mean and standard deviation of each metric\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "\n",
    "        # Print the compiled results\n",
    "        print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "        print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "        print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "        print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "\n",
    "# After all folds, calculate the mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_precision = np.std(precisions)\n",
    "std_recall = np.std(recalls)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the compiled results\n",
    "print(\"Overall Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "print(\"Overall Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "print(\"Overall Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "print(\"Overall Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a1d7e-1ae7-4592-918e-0d2c36f77f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277a243-2e6c-4805-b019-af3229c71a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier  # Import XGBoost classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize KFold with 7 splits (as per your code)\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=5)\n",
    "\n",
    "# Lists to store the metrics for each fold\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "# Define different XGBoost hyperparameters\n",
    "n_estimators_values = [50, 100, 150]  # Number of trees in XGBoost\n",
    "max_depth_values = [3, 5,7]  # Maximum depth of trees in XGBoost\n",
    "num=1\n",
    "for dataset in dataSets:\n",
    "    print(num)\n",
    "    num=num+1\n",
    "    # Assuming 'dataset' is your dataset and it has features and a target column\n",
    "    X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "    y = dataset['defects']  # Target column\n",
    "\n",
    "    # Loop through different hyperparameter combinations for XGBoost\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            fold_num = 1\n",
    "\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                # Split data into train and test for this fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                # Feature selection with RandomForest\n",
    "                model = RandomForestClassifier(random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                num_features_to_select = int(.4* X_train.shape[1])  # Select top 60% of features\n",
    "                feature_importances = model.feature_importances_\n",
    "                indices = np.argsort(feature_importances)[::-1]  # Sort feature importances in descending order\n",
    "                selected_features = X_train.columns[indices[:num_features_to_select]]  # Select top features\n",
    "\n",
    "                print(f\"Top {num_features_to_select} selected features: {list(selected_features)}\")\n",
    "\n",
    "                # Transform the train and test sets to only include the selected features\n",
    "                X_train_selected = X_train[selected_features]\n",
    "                X_test_selected = X_test[selected_features]\n",
    "\n",
    "                # Plot graph of feature importances for selected features\n",
    "                selected_feat_importances = pd.Series(feature_importances, index=X_train.columns)[selected_features]\n",
    "                selected_feat_importances.sort_values(ascending=False).plot(kind='barh')\n",
    "                plt.title(\"Feature Importances for Selected Features\")\n",
    "                plt.show()\n",
    "\n",
    "                # Initialize the XGBoost model with the current hyperparameters\n",
    "                clf = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "                # Check for unique classes\n",
    "                print(\"Unique classes in y_train:\", np.unique(y_train))\n",
    "\n",
    "               \n",
    "                le = LabelEncoder()\n",
    "                y_train = le.fit_transform(y_train)\n",
    "\n",
    "                # Train the XGBoost model on the selected features\n",
    "                clf.fit(X_train_selected, y_train)\n",
    "    \n",
    "                # Predict on the test data with selected features\n",
    "                y_pred = clf.predict(X_test_selected)\n",
    "\n",
    "                # Calculate metrics\n",
    "                DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "                DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "                DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "                # Append metrics to lists\n",
    "                accuracies.append(DT_accuracy)\n",
    "                precisions.append(DT_precision)\n",
    "                recalls.append(DT_recall)\n",
    "                f1_scores.append(DT_f1)\n",
    "\n",
    "                # Print metrics for this fold and hyperparameter combination\n",
    "                print(f\"Fold {fold_num} - XGBoost with n_estimators={n_estimators}, max_depth={max_depth}\")\n",
    "                print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "                print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "                print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "                print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "                print(\"-\" * 30)\n",
    "                fold_num += 1\n",
    "\n",
    "            print(f\"XGBoost with n_estimators={n_estimators}, max_depth={max_depth}:\")\n",
    "            # After all folds, calculate the mean and standard deviation of each metric\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            mean_precision = np.mean(precisions)\n",
    "            mean_recall = np.mean(recalls)\n",
    "            mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "            std_accuracy = np.std(accuracies)\n",
    "            std_precision = np.std(precisions)\n",
    "            std_recall = np.std(recalls)\n",
    "            std_f1 = np.std(f1_scores)\n",
    "\n",
    "            # Print the compiled results\n",
    "            print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "            print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "            print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "            print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "\n",
    "# After all folds, calculate the overall mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "std_accuracy = np.std(accuracies)\n",
    "std_precision = np.std(precisions)\n",
    "std_recall = np.std(recalls)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "# Print the final compiled results\n",
    "print(\"Overall Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "print(\"Overall Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "print(\"Overall Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "print(\"Overall Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101749df-5a74-4246-b4b5-40fe4fcd5392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier  # Import XGBoost classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize KFold with 7 splits (as per your code)\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=5)\n",
    "\n",
    "\n",
    "# Define different XGBoost hyperparameters\n",
    "# n_estimators_values = [50, 100, 150]  # Number of trees in XGBoost\n",
    "# max_depth_values = [3, 5,7]  # Maximum depth of trees in XGBoost\n",
    "\n",
    "n_estimators_values = [50]  # Number of trees in XGBoost\n",
    "max_depth_values = [5]  # Maximum depth of trees in XGBoost\n",
    "num=1\n",
    "for n_estimators in n_estimators_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        for dataset in dataSets:\n",
    "            print(num)\n",
    "            num=num+1\n",
    "            # Assuming 'dataset' is your dataset and it has features and a target column\n",
    "            X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "            y = dataset['defects']  # Target column\n",
    "            # Loop through different hyperparameter combinations for XGBoost\n",
    "            fold_num = 1\n",
    "\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                # Split data into train and test for this fold\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                # Feature selection with RandomForest\n",
    "                model = RandomForestClassifier(random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                num_features_to_select = int(0.9* X_train.shape[1])  # Select top 60% of features\n",
    "                feature_importances = model.feature_importances_\n",
    "                indices = np.argsort(feature_importances)[::-1]  # Sort feature importances in descending order\n",
    "                selected_features = X_train.columns[indices[:num_features_to_select]]  # Select top features\n",
    "                print(f\"Top {num_features_to_select} selected features: out of {X_train.shape[1]}\")\n",
    "                # print(f\"Top {num_features_to_select} selected features: {list(selected_features)}\")\n",
    "\n",
    "                # Transform the train and test sets to only include the selected features\n",
    "                X_train_selected = X_train[selected_features]\n",
    "                X_test_selected = X_test[selected_features]\n",
    "\n",
    "                # # Plot graph of feature importances for selected features\n",
    "                # selected_feat_importances = pd.Series(feature_importances, index=X_train.columns)[selected_features]\n",
    "                # selected_feat_importances.sort_values(ascending=False).plot(kind='barh')\n",
    "                # plt.title(\"Feature Importances for Selected Features\")\n",
    "                # plt.show()\n",
    "\n",
    "                # Initialize the XGBoost model with the current hyperparameters\n",
    "                clf = XGBClassifier(n_estimators=n_estimators, \n",
    "                    max_depth=max_depth, \n",
    "                    learning_rate=0.1,  # Set ETA to 0.1\n",
    "                    random_state=42, \n",
    "                    use_label_encoder=False, \n",
    "                    eval_metric='logloss')\n",
    "                # Check for unique classes\n",
    "                print(\"Unique classes in y_train:\", np.unique(y_train))\n",
    "\n",
    "               \n",
    "                le = LabelEncoder()\n",
    "                y_train = le.fit_transform(y_train)\n",
    "\n",
    "                # Train the XGBoost model on the selected features\n",
    "                clf.fit(X_train_selected, y_train)\n",
    "    \n",
    "                # Predict on the test data with selected features\n",
    "                y_pred = clf.predict(X_test_selected)\n",
    "\n",
    "                # Calculate metrics\n",
    "                DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "                DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "                DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "                # Append metrics to lists\n",
    "                accuracies.append(DT_accuracy)\n",
    "                precisions.append(DT_precision)\n",
    "                recalls.append(DT_recall)\n",
    "                f1_scores.append(DT_f1)\n",
    "\n",
    "                # Print metrics for this fold and hyperparameter combination\n",
    "                # print(f\"Fold {fold_num} - XGBoost with n_estimators={n_estimators}, max_depth={max_depth}\")\n",
    "                # print(\"Accuracy: {:.2f}\".format(DT_accuracy))\n",
    "                # print(\"Precision: {:.2f}\".format(DT_precision))\n",
    "                # print(\"Recall: {:.2f}\".format(DT_recall))\n",
    "                # print(\"F1 score: {:.2f}\".format(DT_f1))\n",
    "                # print(\"-\" * 30)\n",
    "                fold_num += 1\n",
    "\n",
    "            # print(f\"XGBoost with n_estimators={n_estimators}, max_depth={max_depth}:\")\n",
    "            # After all folds, calculate the mean and standard deviation of each metric\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            mean_precision = np.mean(precisions)\n",
    "            mean_recall = np.mean(recalls)\n",
    "            mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "            std_accuracy = np.std(accuracies)\n",
    "            std_precision = np.std(precisions)\n",
    "            std_recall = np.std(recalls)\n",
    "            std_f1 = np.std(f1_scores)\n",
    "\n",
    "            # Print the compiled results\n",
    "            # print(\"Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "            # print(\"Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "            # print(\"Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "            # print(\"Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))\n",
    "        # After all folds, calculate the overall mean and standard deviation of each metric\n",
    "        \n",
    "        print(f\"XGBoost with n_estimators={n_estimators}, max_depth={max_depth}:\")\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        std_precision = np.std(precisions)\n",
    "        std_recall = np.std(recalls)\n",
    "        std_f1 = np.std(f1_scores)\n",
    "\n",
    "        # Print the final compiled results\n",
    "        print(\"Overall Mean Accuracy: {:.2f} ± {:.2f}\".format(mean_accuracy, std_accuracy))\n",
    "        print(\"Overall Mean Precision: {:.2f} ± {:.2f}\".format(mean_precision, std_precision))\n",
    "        print(\"Overall Mean Recall: {:.2f} ± {:.2f}\".format(mean_recall, std_recall))\n",
    "        print(\"Overall Mean F1 Score: {:.2f} ± {:.2f}\".format(mean_f1, std_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59640c1-3191-4d91-abde-a2c0c9afaf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier  # Import XGBoost classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize KFold with 3 splits (as per your code)\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=5)\n",
    "\n",
    "# Fixed XGBoost hyperparameters\n",
    "n_estimators = 50  # Number of trees in XGBoost\n",
    "max_depth = 5      # Maximum depth of trees in XGBoost\n",
    "learning_rate = 0.1  # Fixed learning rate (ETA)\n",
    "\n",
    "# Initialize best tracking variables\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "best_f1 = 0\n",
    "best_thresholds = {}  # To store the best thresholds for each metric\n",
    "\n",
    "# Testing different feature selection thresholds from 0.1 to 1.0 in increments of 0.1\n",
    "thresholds = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for dataset in dataSets:\n",
    "        # Assuming 'dataset' is your dataset and it has features and a target column\n",
    "        X = dataset.drop('defects', axis=1)  # Features (drop the target column)\n",
    "        y = dataset['defects']  # Target column\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Split data into train and test for this fold\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Feature selection with RandomForest\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            num_features_to_select = int(threshold * X_train.shape[1])  # Select based on current threshold\n",
    "            feature_importances = model.feature_importances_\n",
    "            indices = np.argsort(feature_importances)[::-1]  # Sort feature importances in descending order\n",
    "            selected_features = X_train.columns[indices[:num_features_to_select]]  # Select top features\n",
    "\n",
    "            # Transform the train and test sets to only include the selected features\n",
    "            X_train_selected = X_train[selected_features]\n",
    "            X_test_selected = X_test[selected_features]\n",
    "\n",
    "            # Initialize the XGBoost model with the fixed hyperparameters\n",
    "            clf = XGBClassifier(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth,\n",
    "                                learning_rate=learning_rate,  # Fixed learning rate\n",
    "                                random_state=42,\n",
    "                                use_label_encoder=False,\n",
    "                                eval_metric='logloss')\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            y_train = le.fit_transform(y_train)\n",
    "\n",
    "            # Train the XGBoost model on the selected features\n",
    "            clf.fit(X_train_selected, y_train)\n",
    "\n",
    "            # Predict on the test data with selected features\n",
    "            y_pred = clf.predict(X_test_selected)\n",
    "\n",
    "            # Calculate metrics\n",
    "            DT_accuracy = accuracy_score(y_test, y_pred)\n",
    "            DT_precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for imbalanced classes\n",
    "            DT_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            DT_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # Append metrics to lists\n",
    "            accuracies.append(DT_accuracy)\n",
    "            precisions.append(DT_precision)\n",
    "            recalls.append(DT_recall)\n",
    "            f1_scores.append(DT_f1)\n",
    "\n",
    "    # After all folds, calculate the mean of each metric\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "    # Track the best metrics and update parameters if the current combination is better\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_thresholds['accuracy'] = threshold\n",
    "\n",
    "    if mean_precision > best_precision:\n",
    "        best_precision = mean_precision\n",
    "        best_thresholds['precision'] = threshold\n",
    "\n",
    "    if mean_recall > best_recall:\n",
    "        best_recall = mean_recall\n",
    "        best_thresholds['recall'] = threshold\n",
    "\n",
    "    if mean_f1 > best_f1:\n",
    "        best_f1 = mean_f1\n",
    "        best_thresholds['f1'] = threshold\n",
    "\n",
    "# After all combinations, print the best results and their corresponding thresholds\n",
    "print(\"\\nBest Results:\")\n",
    "print(\"Highest Accuracy: {:.2f} with feature selection threshold={:.1f}\".format(\n",
    "    best_accuracy, best_thresholds['accuracy']))\n",
    "print(\"Highest Precision: {:.2f} with feature selection threshold={:.1f}\".format(\n",
    "    best_precision, best_thresholds['precision']))\n",
    "print(\"Highest Recall: {:.2f} with feature selection threshold={:.1f}\".format(\n",
    "    best_recall, best_thresholds['recall']))\n",
    "print(\"Highest F1 Score: {:.2f} with feature selection threshold={:.1f}\".format(\n",
    "    best_f1, best_thresholds['f1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fb9df-a0d3-4bbe-b6cd-df7056fb1900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
